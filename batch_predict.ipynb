{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A notebook that runs UNet prediction in batches\n",
    "\n",
    "by only loading the model once to the gpu prediction is much faster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import os \n",
    "import argparse\n",
    "import logging\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "sys.path.insert(0,\"./Pytorch-UNet/\")\n",
    "from utils.data_loading import BasicDataset\n",
    "from unet import UNet\n",
    "from utils.utils import plot_img_and_mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add relevant functions:\n",
    "\n",
    "def predict_img(net,\n",
    "                full_img,\n",
    "                device,\n",
    "                scale_factor=1,\n",
    "                out_threshold=0.5):\n",
    "    net.eval()\n",
    "    img = torch.from_numpy(BasicDataset.preprocess(None, full_img, scale_factor, is_mask=False))\n",
    "    img = img.unsqueeze(0)\n",
    "    img = img.to(device=device, dtype=torch.float32)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = net(img).cpu()\n",
    "        output = F.interpolate(output, (full_img.size[1], full_img.size[0]), mode='bilinear')\n",
    "        if net.n_classes > 1:\n",
    "            mask = output.argmax(dim=1)\n",
    "        else:\n",
    "            mask = torch.sigmoid(output) > out_threshold\n",
    "\n",
    "    return mask[0].long().squeeze().numpy()\n",
    "\n",
    "\n",
    "\n",
    "def mask_to_image(mask: np.ndarray, mask_values):\n",
    "    if isinstance(mask_values[0], list):\n",
    "        out = np.zeros((mask.shape[-2], mask.shape[-1], len(mask_values[0])), dtype=np.uint8)\n",
    "    elif mask_values == [0, 1]:\n",
    "        out = np.zeros((mask.shape[-2], mask.shape[-1]), dtype=bool)\n",
    "    else:\n",
    "        out = np.zeros((mask.shape[-2], mask.shape[-1]), dtype=np.uint8)\n",
    "\n",
    "    if mask.ndim == 3:\n",
    "        mask = np.argmax(mask, axis=0)\n",
    "\n",
    "    for i, v in enumerate(mask_values):\n",
    "        out[mask == i] = v\n",
    "\n",
    "    return Image.fromarray(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize cuda \n",
    "\n",
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  # use GPU with index 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total GPU Memory: 12198.38 MB\n",
      "Allocated GPU Memory: 0.00 MB\n",
      "Free GPU Memory: 12198.38 MB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    # Get the default CUDA device\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    # Query the available memory\n",
    "    total_memory = torch.cuda.get_device_properties(device).total_memory\n",
    "    allocated_memory = torch.cuda.memory_allocated(device)\n",
    "    free_memory = total_memory - allocated_memory\n",
    "\n",
    "    print(f\"Total GPU Memory: {total_memory / 1024**2:.2f} MB\")\n",
    "    print(f\"Allocated GPU Memory: {allocated_memory / 1024**2:.2f} MB\")\n",
    "    print(f\"Free GPU Memory: {free_memory / 1024**2:.2f} MB\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify input paramaters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = '/home/lmeyers/paintDetect/images/testing/'\n",
    "model = '/home/lmeyers/paintDetect/wandb/latest-run/files/model.pth'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code will create a new timestamped directory in the mask folder where predictions will be saved. \n",
    "It wil then load the model to the gpu and call each file in the image_dir and save with a .pred.jpg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "directory_name = f\"/home/lmeyers/paintDetect/masks/predict_{current_date}\"\n",
    "os.mkdir(directory_name)\n",
    "\n",
    "#image_dir = \"/home/lmeyers/paintDetect/images/testing/\"\n",
    "\n",
    "\n",
    "in_files = []\n",
    "out_files = []\n",
    "\n",
    "dir_list = os.walk(image_dir)\n",
    "for root, dirs, files in dir_list:\n",
    "    for f in files: \n",
    "        #print(root+f)\n",
    "        in_files.append(root+f)\n",
    "        out_files.append(f\"/home/lmeyers/paintDetect/masks/predict_{current_date}/\"+f[:-4]+'.pred.jpg')\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "\n",
    "\n",
    "model = '/home/lmeyers/paintDetect/wandb/latest-run/files/model.pth'\n",
    "\n",
    "net = UNet(n_channels=3, n_classes=2, bilinear=False)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "logging.info(f'Loading model {model}')\n",
    "logging.info(f'Using device {device}')\n",
    "\n",
    "net.to(device=device)\n",
    "state_dict = torch.load(model, map_location=device)\n",
    "mask_values = state_dict.pop('mask_values', [0, 1])\n",
    "net.load_state_dict(state_dict)\n",
    "\n",
    "logging.info('Model loaded!')\n",
    "\n",
    "for i, filename in enumerate(in_files):\n",
    "    logging.info(f'Predicting image {filename} ...')\n",
    "    img = Image.open(filename)\n",
    "\n",
    "    mask = predict_img(net=net,\n",
    "                        full_img=img,\n",
    "                        scale_factor=1,\n",
    "                        out_threshold=.5,\n",
    "                        device=device)\n",
    "\n",
    "   \n",
    "    out_filename = out_files[i]\n",
    "    result = mask_to_image(mask, mask_values)\n",
    "    result.save(out_filename)\n",
    "    logging.info(f'Mask saved to {out_filename}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
